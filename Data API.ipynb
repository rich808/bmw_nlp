{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import request library\n",
    "import requests \n",
    "import time # to delay the scrape time\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inquire(subreddit, days, n):\n",
    "    col = ['title', 'selftext', 'subreddit', 'created_utc', 'author', 'num_comments', 'score', 'is_self']\n",
    "    \n",
    "    #base url and parameters:\n",
    "    base_url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "    \n",
    "    #days to get post\n",
    "    days = days #this mean to get post after 'days'ago. get post from 1 day ago, after 2 days ago, ...\n",
    "    \n",
    "    #empty list to add into the dictionary created from json\n",
    "    posts = []\n",
    "    \n",
    "    #repeat n times, size each time request is limited to 500 post. look for at least 2000\n",
    "    #start from 1 and include iself.\n",
    "    for i in range(1, n+1):\n",
    "        \n",
    "        #send url request\n",
    "        re = requests.get(base_url,\n",
    "                          params = {\n",
    "                              'subreddit' : subreddit,\n",
    "                              'size' : 500,\n",
    "                              'after' : f'{days*i}d'\n",
    "                          })\n",
    "        \n",
    "        #add statment to check status\n",
    "        print(f'Completed requet for {subreddit} for {days*i} day(s)')\n",
    "        \n",
    "        #add assert incase the request was bad so we know\n",
    "        assert re.status_code == 200\n",
    "        \n",
    "        #convert to json with just the data section\n",
    "        json = re.json()['data']\n",
    "        \n",
    "        #convert json to df\n",
    "        df = pd.DataFrame(json)\n",
    "        \n",
    "        #add dictionary to the posts\n",
    "        posts.append(df)\n",
    "        \n",
    "        #give it a pause of 2 second for each request\n",
    "        time.sleep(2)\n",
    "        \n",
    "    #combine each posts into one full list\n",
    "    combine = pd.concat(posts, sort = False)\n",
    "    \n",
    "    #clean the data. Remove duplicates, and only contain is_self post, so no repost\n",
    "    combine = combine[col]\n",
    "    \n",
    "    combine.drop_duplicates(inplace = True)\n",
    "    \n",
    "    combine = combine.loc[combine['is_self'] == True]\n",
    "    \n",
    "    #add the converted time column for each post\n",
    "    combine['time_date'] = combine['created_utc'].map(dt.date.fromtimestamp)\n",
    "    \n",
    "    #indicator for finish\n",
    "    print('Request Completed')\n",
    "    \n",
    "    return combine\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed requet for e46 for 60 day(s)\n",
      "Completed requet for e46 for 120 day(s)\n",
      "Completed requet for e46 for 180 day(s)\n",
      "Completed requet for e46 for 240 day(s)\n",
      "Completed requet for e46 for 300 day(s)\n",
      "Completed requet for e46 for 360 day(s)\n",
      "Completed requet for e46 for 420 day(s)\n",
      "Completed requet for e46 for 480 day(s)\n",
      "Completed requet for e46 for 540 day(s)\n",
      "Completed requet for e46 for 600 day(s)\n",
      "Request Completed\n"
     ]
    }
   ],
   "source": [
    "e_46 = inquire('e46', 60, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2062"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e_46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed requet for E90 for 60 day(s)\n",
      "Completed requet for E90 for 120 day(s)\n",
      "Completed requet for E90 for 180 day(s)\n",
      "Completed requet for E90 for 240 day(s)\n",
      "Completed requet for E90 for 300 day(s)\n",
      "Completed requet for E90 for 360 day(s)\n",
      "Completed requet for E90 for 420 day(s)\n",
      "Completed requet for E90 for 480 day(s)\n",
      "Completed requet for E90 for 540 day(s)\n",
      "Completed requet for E90 for 600 day(s)\n",
      "Completed requet for E90 for 660 day(s)\n",
      "Completed requet for E90 for 720 day(s)\n",
      "Completed requet for E90 for 780 day(s)\n",
      "Completed requet for E90 for 840 day(s)\n",
      "Completed requet for E90 for 900 day(s)\n",
      "Request Completed\n"
     ]
    }
   ],
   "source": [
    "e_90 = inquire('E90', 60, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1906"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to CSV for EDA, and modeling.\n",
    "\n",
    "e_46.to_csv('./data/e_46.csv', index = False)\n",
    "e_90.to_csv('./data/e_90.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
